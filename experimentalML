import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
from PIL import Image
import tensorflow as tf
tf.get_logger().setLevel('ERROR')
import logging

class OutfitRater:
    def __init__(self, base_path, labels_file):
        self.base_path = base_path
        self.labels_file = labels_file
        self.keypoints = {}
        self.fabric_annotations = {}
        self.load_annotations()
        self.build_model()

    def load_annotations(self):
        logging.info("Loading annotations...")
        
        with open(self.labels_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                filename = parts[0]
                fabric_type = int(parts[3])  # Adjust based on file structure
                style_label = self.map_fabric_to_label(fabric_type)
                self.fabric_annotations[filename] = style_label
        logging.info(f"Loaded {len(self.fabric_annotations)} fabric annotations")

    def map_fabric_to_label(self, fabric_type):
        """Convert fabric type from file to a style label."""
        casual_types = {7, 1}  # e.g., denim, cotton
        formal_types = {2}     # e.g., silk, wool
        
        if fabric_type in casual_types:
            return 0  # casual
        elif fabric_type in formal_types:
            return 1  # formal
        return -1  # unknown

    def calculate_fit_score(self, keypoints):
        if 'left_shoulder' in keypoints and 'right_shoulder' in keypoints and \
           'left_hip' in keypoints and 'right_hip' in keypoints:
            shoulder_width = np.linalg.norm(keypoints['left_shoulder'] - keypoints['right_shoulder'])
            hip_width = np.linalg.norm(keypoints['left_hip'] - keypoints['right_hip'])
            target_ratio = 1.0
            actual_ratio = shoulder_width / hip_width
            fit_score = max(0, 1 - abs(actual_ratio - target_ratio))
            return fit_score * 100  # Scale to 0-100
        return 50.0  # Default if keypoints are missing
    
    
    def calculate_color_harmony_score(self, img_array):
        downsampled_img = Image.fromarray((img_array * 255).astype(np.uint8)).resize((64, 64))
        img_array_flat = np.array(downsampled_img).reshape(-1, 3)
        
        num_samples = min(50, img_array_flat.shape[0])  # Use fewer samples if not enough pixels
        if num_samples < 2:
            return 0  # Return a default score if not enough pixels
        
        sampled_pixels = img_array_flat[np.random.choice(img_array_flat.shape[0], num_samples, replace=False)]
        
        color_diffs = np.linalg.norm(sampled_pixels[:, np.newaxis] - sampled_pixels, axis=2)
        
        harmony_score = np.sum((color_diffs < 100) & (color_diffs > 0))
        max_possible_pairs = num_samples * (num_samples - 1) / 2
        return harmony_score / max_possible_pairs


    
    def calculate_style_score(self, fabric_type):
        if fabric_type in {7, 1}:  # Example: denim, cotton
            return 0  # Casual
        elif fabric_type in {2}:  # Example: silk, wool
            return 1  # Formal
        return 0.5  # Neutral score if unknown

    def build_model(self):
        backbone = tf.keras.applications.ResNet50(
            include_top=False,
            weights='imagenet',
            input_shape=(224, 224, 3)
        )
        
        inputs = tf.keras.Input(shape=(224, 224, 3))
        x = backbone(inputs)
        shared = tf.keras.layers.GlobalAveragePooling2D()(x)

        color_harmony = tf.keras.layers.Dense(64, activation='relu')(shared)
        color_harmony = tf.keras.layers.Dense(1, name='color_score')(color_harmony)

        fit_proportion = tf.keras.layers.Dense(64, activation='relu')(shared)
        fit_proportion = tf.keras.layers.Dense(1, name='fit_score')(fit_proportion)

        style = tf.keras.layers.Dense(64, activation='relu')(shared)
        style = tf.keras.layers.Dense(1, name='style_score')(style)

        self.model = tf.keras.Model(inputs=inputs, outputs=[color_harmony, fit_proportion, style])

    def prepare_training_data(self, max_images=10):  
        X = []
        y_color = []
        y_fit = []
        y_style = []

        images_path = os.path.join(self.base_path, 'images')
        if not os.path.exists(images_path):
            raise FileNotFoundError(f"Images directory not found at: {images_path}")

        for idx, image_file in enumerate(os.listdir(images_path)):
            if idx >= max_images:  
                break
            
            img_path = os.path.join(images_path, image_file)
            
            if image_file not in self.fabric_annotations:
                continue  # Skip images without style labels

            try:
                with Image.open(img_path) as img:
                    img = img.convert('RGB').resize((224, 224))
                    img_array = np.array(img, dtype=np.float32) / 255.0

                color_score = self.calculate_color_harmony_score(img_array)
                fit_score = self.calculate_fit_score(self.keypoints.get(image_file, {}))
                fabric_type = self.fabric_annotations.get(image_file, -1)
                style_score = self.calculate_style_score(fabric_type)
                
                if fabric_type == -1:
                    continue  # Skip if unknown label

                X.append(img_array)
                y_color.append([color_score])
                y_fit.append([fit_score])
                y_style.append([style_score])

            except Exception as e:
                logging.error(f"Error processing image {image_file}: {e}")
                continue

        return np.array(X), [np.array(y_color), np.array(y_fit), np.array(y_style)]



    def train(self, epochs=10):
        X, y = self.prepare_training_data()
        
        self.model.compile(
            optimizer='adam',
            loss={'color_score': 'mse', 'fit_score': 'mse', 'style_score': 'binary_crossentropy'},
            metrics={'color_score': 'mae', 'fit_score': 'mae', 'style_score': 'accuracy'}
        )
        
        history = self.model.fit(
            X, y,
            epochs=epochs,
            validation_split=0.2,
            batch_size=8,
            verbose=1
        )
        return history

    def rate_outfit(self, image_path):
        try:
            with Image.open(image_path) as img:
                img = img.convert('RGB').resize((224, 224))
                img_array = np.array(img, dtype=np.float32) / 255.0
                img_array = np.expand_dims(img_array, axis=0)

            color_score, fit_score, style_score = self.model.predict(img_array)

            result = {
                'color_harmony': float(color_score[0][0]),
                'fit_proportion': float(fit_score[0][0]),
                'style': 'formal' if style_score[0][0] > 0.5 else 'casual'  # Classify based on threshold
            }
            return result
        except Exception as e:
            logging.error(f"Error rating outfit: {e}")
            raise

if __name__ == "__main__":
    base_path = 'C:/Users/svenx/Downloads/DeepFashion-MultiModal'
    labels_file = 'C:/Users/svenx/Downloads/DeepFashion-MultiModal/labels/texture/fabric_ann.txt'
    rater = OutfitRater(base_path, labels_file)
    rater.train(epochs=10)
    result = rater.rate_outfit("C:/Users/svenx/Downloads/cas.jpg")
    print("Final result:", result)i want it to analyze cas.jpg and give it a  score based on style, harmony, and fit
